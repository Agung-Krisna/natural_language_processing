{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Similarity Matrix\nSimilarity matrix merupakan sebuah *method* yang digunakan untuk menciptakan sebuah matriks 2 dimensi yang nantinya akan diisi dengan nilai kemiripan kosinus (cosine similarity) yang didapatkan dari *method* `sentence_similarity`. \n\n```python\ndef __similarity_matrix(self):\n        similarity_matrix = np.zeros((len(self.__word), len(self.__word)))\n        for index1 in range(len(self.__word)):\n            for index2 in range(len(self.__word)):\n                if index1 == index2:\n                    continue\n                similarity_matrix[index1][index2] = self.__sentence_similarity(self.__word[index1], self.__word[index2])\n        return similarity_matrix\n```",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Hal pertama yang perlu dilakukan adalah menginisialisasikan sebuah matriks 2 dimensi dengan panjang `self.__word` x `self.__word`. \n```python\nsimilarity_matrix = np.zeros((len(self.__word), len(self.__word)))\n```\nKeluaran dari potongan kode diatas dapat dilihat dibawah ini.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nword = \"For oil spots on the floor, nothing beats parking a motorbike in the lounge. Tom got a small piece of pie. The hand sanitizer was actually clear glue\".split()\nsimilarity_matrix = np.zeros((len(word), len(word)))\nprint(similarity_matrix)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]\n [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n  0. 0. 0. 0.]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Hal selanjutnya yang perlu dilakukan adalah menghitung similarity dari pasangan kata dan menyimpannya kedalam matriks `similarity_matrix`.\n```python\nfor index1 in range(len(self.__word)):\n    for index2 in range(len(self.__word)):\n        if index1 == index2:\n            continue\n        similarity_matrix[index1][index2] = self.__sentence_similarity(self.__word[index1], self.__word[index2])\n```\n> Perhatikan bahwa terdapat pengecekan kondisi `if index1 == index2: continue`, hal tersebut ditujukan agar program tidak mengecek tingkat kemiripan antara sebuah kata dengan dirinya sendiri.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "## already explained in another notebook.\nfrom nltk.cluster.util import cosine_distance\ndef sentence_similarity(sentence1, sentence2):\n        sentence1 = [word for word in sentence1]\n        sentence2 = [word for word in sentence2]\n        all_words = list(set(sentence1+sentence2))\n        vector1 = [0] * len(all_words)\n        vector2 = [0] * len(all_words)\n        for w in sentence1:\n            vector1[all_words.index(w)] += 1\n        for w in sentence2:\n            vector2[all_words.index(w)] += 1\n        return 1 - cosine_distance(vector1, vector2)\n\n## will be focusing on this part of the code.\nfor index1 in range(len(word)):\n    for index2 in range(len(word)):\n        if index1 == index2:\n            continue\n        similarity_matrix[index1][index2] = sentence_similarity(word[index1], word[index2])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Hal terakhir yang perlu dilakukan adalah mengembalikan (return) nilai dari `similarity_matrix`.\n```python \nreturn similarity_matrix\n```\nHasil keluaran `similarity_matrix` akan digunakan pada kalkulasi selanjutnya, yaitu pembuatan sebuah grafik sebagai basis dari algoritma TextRank.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "print(similarity_matrix)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "text": "[[0.         0.33333333 0.21821789 0.40824829 0.         0.61237244\n  0.19245009 0.         0.21821789 0.         0.52223297 0.\n  0.         0.21821789 0.33333333 0.33333333 0.         0.\n  0.         0.40824829 0.         0.         0.         0.17407766\n  0.         0.         0.25819889 0.        ]\n [0.33333333 0.         0.21821789 0.40824829 0.         0.61237244\n  0.38490018 0.         0.21821789 0.         0.52223297 0.40824829\n  0.         0.43643578 0.33333333 0.33333333 0.         0.43643578\n  0.21821789 0.40824829 0.28867513 0.         0.         0.34815531\n  0.         0.33333333 0.25819889 0.28867513]\n [0.21821789 0.21821789 0.         0.26726124 0.21821789 0.26726124\n  0.25197632 0.50709255 0.14285714 0.         0.34188173 0.\n  0.21821789 0.14285714 0.21821789 0.43643578 0.         0.28571429\n  0.14285714 0.26726124 0.18898224 0.         0.         0.34188173\n  0.43643578 0.10910895 0.         0.        ]\n [0.40824829 0.40824829 0.26726124 0.         0.         0.5\n  0.70710678 0.         0.26726124 0.         0.42640143 0.5\n  0.         0.53452248 0.40824829 0.40824829 0.         0.\n  0.         0.5        0.         0.         0.35355339 0.21320072\n  0.         0.         0.         0.        ]\n [0.         0.         0.21821789 0.         0.         0.\n  0.38490018 0.51639778 0.         0.         0.34815531 0.\n  1.         0.21821789 0.         0.33333333 0.         0.\n  0.43643578 0.         0.28867513 0.66666667 0.28867513 0.34815531\n  0.         0.16666667 0.25819889 0.28867513]\n [0.61237244 0.61237244 0.26726124 0.5        0.         0.\n  0.23570226 0.         0.13363062 0.         0.53300179 0.\n  0.         0.40089186 0.40824829 0.40824829 0.         0.26726124\n  0.         0.75       0.         0.         0.         0.10660036\n  0.         0.20412415 0.31622777 0.1767767 ]\n [0.19245009 0.38490018 0.25197632 0.70710678 0.38490018 0.23570226\n  0.         0.1490712  0.50395263 0.         0.40201513 0.70710678\n  0.38490018 0.50395263 0.19245009 0.57735027 0.         0.\n  0.12598816 0.23570226 0.16666667 0.19245009 0.5        0.50251891\n  0.         0.09622504 0.         0.16666667]\n [0.         0.         0.50709255 0.         0.51639778 0.\n  0.1490712  0.         0.16903085 0.4472136  0.40451992 0.\n  0.51639778 0.16903085 0.         0.25819889 0.4472136  0.3380617\n  0.3380617  0.         0.2236068  0.25819889 0.2236068  0.53935989\n  0.51639778 0.38729833 0.4        0.2236068 ]\n [0.21821789 0.21821789 0.14285714 0.26726124 0.         0.13363062\n  0.50395263 0.16903085 0.         0.37796447 0.34188173 0.53452248\n  0.         0.28571429 0.         0.21821789 0.37796447 0.14285714\n  0.28571429 0.         0.37796447 0.         0.37796447 0.56980288\n  0.21821789 0.21821789 0.3380617  0.18898224]\n [0.         0.         0.         0.         0.         0.\n  0.         0.4472136  0.37796447 0.         0.         0.\n  0.         0.         0.         0.         1.         0.37796447\n  0.         0.         0.         0.         0.5        0.30151134\n  0.57735027 0.57735027 0.4472136  0.        ]\n [0.52223297 0.52223297 0.34188173 0.42640143 0.34815531 0.53300179\n  0.40201513 0.40451992 0.34188173 0.         0.         0.21320072\n  0.34815531 0.34188173 0.52223297 0.52223297 0.         0.11396058\n  0.34188173 0.42640143 0.30151134 0.17407766 0.         0.45454545\n  0.         0.08703883 0.26967994 0.15075567]\n [0.         0.40824829 0.         0.5        0.         0.\n  0.70710678 0.         0.53452248 0.         0.21320072 0.\n  0.         0.26726124 0.         0.         0.         0.\n  0.26726124 0.         0.35355339 0.         0.35355339 0.63960215\n  0.         0.         0.         0.        ]\n [0.         0.         0.21821789 0.         1.         0.\n  0.38490018 0.51639778 0.         0.         0.34815531 0.\n  0.         0.21821789 0.         0.33333333 0.         0.\n  0.43643578 0.         0.28867513 0.66666667 0.28867513 0.34815531\n  0.         0.16666667 0.25819889 0.28867513]\n [0.21821789 0.43643578 0.14285714 0.53452248 0.21821789 0.40089186\n  0.50395263 0.16903085 0.28571429 0.         0.34188173 0.26726124\n  0.21821789 0.         0.21821789 0.43643578 0.         0.28571429\n  0.28571429 0.26726124 0.37796447 0.21821789 0.18898224 0.22792115\n  0.         0.32732684 0.3380617  0.75592895]\n [0.33333333 0.33333333 0.21821789 0.40824829 0.         0.40824829\n  0.19245009 0.         0.         0.         0.52223297 0.\n  0.         0.21821789 0.         0.33333333 0.         0.21821789\n  0.         0.40824829 0.         0.33333333 0.         0.\n  0.         0.         0.         0.        ]\n [0.33333333 0.33333333 0.43643578 0.40824829 0.33333333 0.40824829\n  0.57735027 0.25819889 0.21821789 0.         0.52223297 0.\n  0.33333333 0.43643578 0.33333333 0.         0.         0.\n  0.         0.40824829 0.         0.         0.         0.17407766\n  0.         0.16666667 0.         0.28867513]\n [0.         0.         0.         0.         0.         0.\n  0.         0.4472136  0.37796447 1.         0.         0.\n  0.         0.         0.         0.         0.         0.37796447\n  0.         0.         0.         0.         0.5        0.30151134\n  0.57735027 0.57735027 0.4472136  0.        ]\n [0.         0.43643578 0.28571429 0.         0.         0.26726124\n  0.         0.3380617  0.14285714 0.37796447 0.11396058 0.\n  0.         0.28571429 0.21821789 0.         0.37796447 0.\n  0.         0.         0.         0.         0.18898224 0.22792115\n  0.43643578 0.65465367 0.50709255 0.37796447]\n [0.         0.21821789 0.14285714 0.         0.43643578 0.\n  0.12598816 0.3380617  0.28571429 0.         0.34188173 0.26726124\n  0.43643578 0.28571429 0.         0.         0.         0.\n  0.         0.         0.75592895 0.43643578 0.         0.45584231\n  0.         0.10910895 0.50709255 0.37796447]\n [0.40824829 0.40824829 0.26726124 0.5        0.         0.75\n  0.23570226 0.         0.         0.         0.42640143 0.\n  0.         0.26726124 0.40824829 0.40824829 0.         0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.28867513 0.18898224 0.         0.28867513 0.\n  0.16666667 0.2236068  0.37796447 0.         0.30151134 0.35355339\n  0.28867513 0.37796447 0.         0.         0.         0.\n  0.75592895 0.         0.         0.28867513 0.         0.45226702\n  0.         0.         0.2236068  0.25      ]\n [0.         0.         0.         0.         0.66666667 0.\n  0.19245009 0.25819889 0.         0.         0.17407766 0.\n  0.66666667 0.21821789 0.33333333 0.         0.         0.\n  0.43643578 0.         0.28867513 0.         0.28867513 0.17407766\n  0.         0.         0.25819889 0.28867513]\n [0.         0.         0.         0.35355339 0.28867513 0.\n  0.5        0.2236068  0.37796447 0.5        0.         0.35355339\n  0.28867513 0.18898224 0.         0.         0.5        0.18898224\n  0.         0.         0.         0.28867513 0.         0.30151134\n  0.28867513 0.28867513 0.2236068  0.        ]\n [0.17407766 0.34815531 0.34188173 0.21320072 0.34815531 0.10660036\n  0.50251891 0.53935989 0.56980288 0.30151134 0.45454545 0.63960215\n  0.34815531 0.22792115 0.         0.17407766 0.30151134 0.22792115\n  0.45584231 0.         0.45226702 0.17407766 0.30151134 0.\n  0.34815531 0.26111648 0.40451992 0.15075567]\n [0.         0.         0.43643578 0.         0.         0.\n  0.         0.51639778 0.21821789 0.57735027 0.         0.\n  0.         0.         0.         0.         0.57735027 0.43643578\n  0.         0.         0.         0.         0.28867513 0.34815531\n  0.         0.33333333 0.25819889 0.        ]\n [0.         0.33333333 0.10910895 0.         0.16666667 0.20412415\n  0.09622504 0.38729833 0.21821789 0.57735027 0.08703883 0.\n  0.16666667 0.32732684 0.         0.16666667 0.57735027 0.65465367\n  0.10910895 0.         0.         0.         0.28867513 0.26111648\n  0.33333333 0.         0.64549722 0.4330127 ]\n [0.25819889 0.25819889 0.         0.         0.25819889 0.31622777\n  0.         0.4        0.3380617  0.4472136  0.26967994 0.\n  0.25819889 0.3380617  0.         0.         0.4472136  0.50709255\n  0.50709255 0.         0.2236068  0.25819889 0.2236068  0.40451992\n  0.25819889 0.64549722 0.         0.4472136 ]\n [0.         0.28867513 0.         0.         0.28867513 0.1767767\n  0.16666667 0.2236068  0.18898224 0.         0.15075567 0.\n  0.28867513 0.75592895 0.         0.28867513 0.         0.37796447\n  0.37796447 0.         0.25       0.28867513 0.         0.15075567\n  0.         0.4330127  0.4472136  0.        ]]\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}